# ðŸŽ¤ Vocal Emotion Analysis â€” Stage 1: Foundation and Initial Model Development

This project focuses on building a deep learning-based **Vocal Emotion Classification** system using a subset of the **RAVDESS** and **CREMA-D** datasets.  
Stage 1 lays the groundwork with **data preparation, visualization, and feature engineering** to create a strong foundation for model development.

---

## ðŸ“Œ Project Overview
The goal of Stage 1 is to:
- Prepare a **structured subset** (20â€“30%) of the datasets.
- Ensure a **balanced distribution** of emotion labels.
- Perform **audio feature visualization** for insights.
- Build a **baseline deep learning model** in the next phase.

---

## ðŸ—‚ Dataset Details
We are using:
- **RAVDESS**: Ryerson Audio-Visual Database of Emotional Speech and Song.
- **CREMA-D**: Crowd-sourced Emotional Multimodal Actors Dataset.

**Subset Selection Criteria:**
- **20â€“30%** of total samples.
- Balanced representation of all emotion classes.
- Saved in a folder hierarchy:

